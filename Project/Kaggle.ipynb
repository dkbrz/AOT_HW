{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/tr2.csv')#, encoding='utf-8-bis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508438, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:/test.csv')\n",
    "test['description'] = test['description'].fillna(value='')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(51):\n",
    "    test['description'][i*10000:(i+1)*10000] = test['description'][i*10000:(i+1)*10000].apply(norm)\n",
    "    print (i, test['description'][i*10000][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('D:/ts.csv', encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    return ' '.join([morph.parse(token)[0].normal_form for token in tknzr.tokenize(text)])\n",
    "norm = np.vectorize(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(151):\n",
    "    train['description'][i*10000:(i+1)*10000] = train['description'][i*10000:(i+1)*10000].apply(norm)\n",
    "    print (i, train['description'][i*10000][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('D:/tr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                  object\n",
       "user_id                  object\n",
       "region                   object\n",
       "city                     object\n",
       "parent_category_name     object\n",
       "category_name            object\n",
       "param_1                  object\n",
       "param_2                  object\n",
       "param_3                  object\n",
       "title                    object\n",
       "description              object\n",
       "price                   float64\n",
       "item_seq_number           int64\n",
       "activation_date          object\n",
       "user_type                object\n",
       "image                    object\n",
       "image_top_1             float64\n",
       "deal_probability        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/tr.csv')\n",
    "#test = pd.read_csv('D:/ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train[['region','city','parent_category_name','category_name','param_1','param_2','param_3','user_type']]\n",
    "train_1 = train_1.fillna(value='')\n",
    "\n",
    "from ce import CategoricalEncoder\n",
    "c = CategoricalEncoder(handle_unknown='ignore')\n",
    "%time c.fit(train_1)\n",
    "\n",
    "train_1 = c.transform(train_1)\n",
    "\n",
    "train_2 = train[['price','item_seq_number','image']]\n",
    "train_2 = train_2.fillna(value=0)\n",
    "\n",
    "train_3 = train[['title']]\n",
    "train_2['title_len'] = train_3['title'].apply(len)\n",
    "train_2 = train_2.to_sparse()\n",
    "\n",
    "del train, train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1503424x3684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12027392 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['image'] = train_2['image'].apply(lambda x: 0 if x is np.nan else 1)\n",
    "train_2 = train_2.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "train = hstack([train_1, train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1503424x3688 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17951080 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('D:/train12.npz', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.externals import joblib\n",
    ">>> joblib.dump(c, 'categorical.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = train[['region','city','parent_category_name','category_name','param_1','param_2','param_3','user_type']]\n",
    "train_2 = train[['price','item_seq_number','image','title']]\n",
    "train_3 = train['description']\n",
    "y_train = train['deal_probability']\n",
    "\n",
    "del train\n",
    "train_2['image'] = train_2['image'].apply(lambda x: 0 if x is np.nan else 1)\n",
    "\n",
    "train_1 = train_1.fillna(value='')\n",
    "train_2 = train_2.fillna(value=0)\n",
    "train_3 = train_3.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CategoricalEncoder(categories='auto', dtype=<class 'numpy.float64'>,\n",
       "          encoding='onehot', handle_unknown='ignore')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ce import CategoricalEncoder\n",
    "c = CategoricalEncoder(handle_unknown='ignore')\n",
    "%time c.fit(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_1 = c.transform(train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1503424x3684 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12027392 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2['title'] = train_3['title'].apply(len)\n",
    "del train_3['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TF-IDF **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/tr.csv')['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(value='')\n",
    "_, train, = train_test_split(train, test_size=0.4, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(601370,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', '...гда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между'],\n",
       "        strip_accents=None, sublinear_tf=False, token_pattern='\\\\S+',\n",
       "        tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = stopwords.words('russian'), ngram_range =(1,3), token_pattern='\\S+', max_features=20000)\n",
    "tfidf.fit(train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.externals import joblib\n",
    ">>> joblib.dump(tfidf, 'tfidf.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** full train **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/tr.csv')['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    ">>> tfidf = joblib.load('D:/tfidf.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfidf.transform(train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('D:/train3.npz', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** full test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('D:/ts.csv')['description']\n",
    "test = test.fillna(value='')\n",
    "test = tfidf.transform(test.values)\n",
    "scipy.sparse.save_npz('D:/test3.npz', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('D:/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.externals import joblib\n",
    ">>> c = joblib.load('categorical.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_1 = test[['region','city','parent_category_name','category_name','param_1','param_2','param_3','user_type']]\n",
    "test_1 = test_1.fillna(value='')\n",
    "\n",
    "test_1 = c.transform(test_1)\n",
    "\n",
    "test_2 = test[['price','item_seq_number','image']]\n",
    "test_2 = test_2.fillna(value=0)\n",
    "\n",
    "test_3 = test[['title']]\n",
    "test_2['title_len'] = test_3['title'].apply(len)\n",
    "test_2 = test_2.to_sparse()\n",
    "\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_3\n",
    "\n",
    "test_2['image'] = test_2['image'].apply(lambda x: 0 if x is np.nan else 1)\n",
    "test_2 = test_2.to_sparse()\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "test = hstack([test_1, test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<508438x3688 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6068627 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('D:/test12.npz', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('D:/tr.csv')['deal_probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from scipy.sparse import hstack\n",
    "train = hstack([scipy.sparse.load_npz('D:/train12.npz'), scipy.sparse.load_npz('D:/train3.npz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1503424x23688 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 66269352 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train\n",
    "\n",
    "test = hstack([scipy.sparse.load_npz('D:/test12.npz'), scipy.sparse.load_npz('D:/test3.npz')])\n",
    "pred = model.predict(test)\n",
    "\n",
    "label = pd.read_csv('D:/ts.csv')['item_id']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['item_id'] = label.values\n",
    "df['deal_probability'] = pred\n",
    "\n",
    "df.to_csv('linear.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred[pred < 0] = 0\n",
    "pred[pred > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['item_id'] = label.values\n",
    "df['deal_probability'] = pred\n",
    "\n",
    "df.to_csv('linear.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ridge **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
